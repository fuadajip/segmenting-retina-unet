
train images/masks shape:
(18, 1, 565, 565)
train images range (min-max): 0.0 - 1.0
train masks are within 0-1

patches per full image: 10000

train PATCHES images/masks shape:
(180000, 1, 27, 27)
train PATCHES images range (min-max): 0.0 - 1.0

train images/masks shape:
(2, 1, 565, 565)
train images range (min-max): 0.0 - 1.0
train masks are within 0-1

patches per full image: 9000

train PATCHES images/masks shape:
(18000, 1, 27, 27)
train PATCHES images range (min-max): 0.0 - 1.0
Check: final output of the network:
(None, 2)
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 1, 27, 27)     0                                            
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (None, 32, 27, 27)    320         input_1[0][0]                    
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 32, 27, 27)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 23328)         0           dropout_1[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 2)             46658       flatten_1[0][0]                  
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 2)             0           dense_1[0][0]                    
====================================================================================================
Total params: 46,978
Trainable params: 46,978
Non-trainable params: 0
____________________________________________________________________________________________________



1  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from inf to 0.24548, saving model to ./test/cnn/test-weights-0.24548.h5
Epoch 00000: val_loss improved from inf to 0.24548, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.2842 - acc: 0.9029 - val_loss: 0.2455 - val_acc: 0.9153
(180000,) (180000,)
162217 175
16143 1465

FA FR TA TR 0.00107763929258 0.91679918219 0.0832008178101 0.998922360707

VALIDATION DATA
0.915277777778 0.245482641194
(18000,) (18000,)
16309 27
1498 166

FA FR TA TR 0.001652791381 0.900240384615 0.0997596153846 0.998347208619
0.245482641194  - val loss
999999  - final_loss
Validation Loss decreased. Great work



2  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.24548 to 0.21507, saving model to ./test/cnn/test-weights-0.21507.h5
Epoch 00000: val_loss improved from 0.24548 to 0.21507, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.2325 - acc: 0.9157 - val_loss: 0.2151 - val_acc: 0.9223
(180000,) (180000,)
161902 490
14278 3330

FA FR TA TR 0.00301739001921 0.810881417537 0.189118582463 0.996982609981

VALIDATION DATA
0.922333333333 0.215068930533
(18000,) (18000,)
16299 37
1361 303

FA FR TA TR 0.00226493633692 0.817908653846 0.182091346154 0.997735063663
0.215068930533  - val loss
0.245482641194  - final_loss
Validation Loss decreased. Great work



3  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.21507 to 0.19358, saving model to ./test/cnn/test-weights-0.19358.h5
Epoch 00000: val_loss improved from 0.21507 to 0.19358, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.2162 - acc: 0.9231 - val_loss: 0.1936 - val_acc: 0.9294
(180000,) (180000,)
161418 974
12170 5438

FA FR TA TR 0.00599783240554 0.691163107678 0.308836892322 0.994002167594

VALIDATION DATA
0.929444444444 0.19357540971
(18000,) (18000,)
16234 102
1168 496

FA FR TA TR 0.00624387855044 0.701923076923 0.298076923077 0.99375612145
0.19357540971  - val loss
0.215068930533  - final_loss
Validation Loss decreased. Great work



4  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.19358 to 0.18996, saving model to ./test/cnn/test-weights-0.18996.h5
Epoch 00000: val_loss improved from 0.19358 to 0.18996, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.2098 - acc: 0.9263 - val_loss: 0.1900 - val_acc: 0.9356
(180000,) (180000,)
160886 1506
10873 6735

FA FR TA TR 0.00927385585497 0.617503407542 0.382496592458 0.990726144145

VALIDATION DATA
0.935611111111 0.189956508206
(18000,) (18000,)
16187 149
1010 654

FA FR TA TR 0.00912095984329 0.606971153846 0.393028846154 0.990879040157
0.189956508206  - val loss
0.19357540971  - final_loss
Validation Loss decreased. Great work



5  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.18996 to 0.18476, saving model to ./test/cnn/test-weights-0.18476.h5
Epoch 00000: val_loss improved from 0.18996 to 0.18476, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.2059 - acc: 0.9282 - val_loss: 0.1848 - val_acc: 0.9351
(180000,) (180000,)
161216 1176
11123 6485

FA FR TA TR 0.00724173604611 0.631701499318 0.368298500682 0.992758263954

VALIDATION DATA
0.935055555556 0.184755440487
(18000,) (18000,)
16218 118
1051 613

FA FR TA TR 0.00722331047992 0.631610576923 0.368389423077 0.99277668952
0.184755440487  - val loss
0.189956508206  - final_loss
Validation Loss decreased. Great work



6  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.18476 to 0.18176, saving model to ./test/cnn/test-weights-0.18176.h5
Epoch 00000: val_loss improved from 0.18476 to 0.18176, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.2032 - acc: 0.9294 - val_loss: 0.1818 - val_acc: 0.9364
(180000,) (180000,)
161155 1237
10756 6852

FA FR TA TR 0.00761737031381 0.610858700591 0.389141299409 0.992382629686

VALIDATION DATA
0.936444444444 0.181758892377
(18000,) (18000,)
16228 108
1036 628

FA FR TA TR 0.006611165524 0.622596153846 0.377403846154 0.993388834476
0.181758892377  - val loss
0.184755440487  - final_loss
Validation Loss decreased. Great work



7  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.18176 to 0.18120, saving model to ./test/cnn/test-weights-0.18120.h5
Epoch 00000: val_loss improved from 0.18176 to 0.18120, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.2024 - acc: 0.9295 - val_loss: 0.1812 - val_acc: 0.9340
(180000,) (180000,)
161508 884
11616 5992

FA FR TA TR 0.00544361791221 0.659700136302 0.340299863698 0.994556382088

VALIDATION DATA
0.934 0.181200382047
(18000,) (18000,)
16259 77
1111 553

FA FR TA TR 0.00471351616063 0.667668269231 0.332331730769 0.995286483839
0.181200382047  - val loss
0.181758892377  - final_loss
Validation Loss decreased. Great work



8  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.2002 - acc: 0.9305 - val_loss: 0.1921 - val_acc: 0.9421
(180000,) (180000,)
159998 2394
9149 8459

FA FR TA TR 0.0147421055224 0.519593366652 0.480406633348 0.985257894478

VALIDATION DATA
0.942055555556 0.192071483745
(18000,) (18000,)
16109 227
816 848

FA FR TA TR 0.0138956904995 0.490384615385 0.509615384615 0.9861043095
0.192071483745  - val loss
0.181200382047  - final_loss
Inside Plateau  1



8  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1987 - acc: 0.9311 - val_loss: 0.1816 - val_acc: 0.9340
(180000,) (180000,)
161580 812
11479 6129

FA FR TA TR 0.00500024631755 0.651919582008 0.348080417992 0.994999753682

VALIDATION DATA
0.934 0.181641548498
(18000,) (18000,)
16269 67
1121 543

FA FR TA TR 0.0041013712047 0.673677884615 0.326322115385 0.995898628795
0.181641548498  - val loss
0.181200382047  - final_loss
Inside Plateau  2



8  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.18120 to 0.17818, saving model to ./test/cnn/test-weights-0.17818.h5
Epoch 00000: val_loss improved from 0.18120 to 0.17818, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.1974 - acc: 0.9313 - val_loss: 0.1782 - val_acc: 0.9412
(180000,) (180000,)
160558 1834
9315 8293

FA FR TA TR 0.0112936597862 0.529020899591 0.470979100409 0.988706340214

VALIDATION DATA
0.941222222222 0.178184453415
(18000,) (18000,)
16192 144
914 750

FA FR TA TR 0.00881488736533 0.549278846154 0.450721153846 0.991185112635
0.178184453415  - val loss
0.181200382047  - final_loss
Validation Loss decreased. Great work



9  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.17818 to 0.17574, saving model to ./test/cnn/test-weights-0.17574.h5
Epoch 00000: val_loss improved from 0.17818 to 0.17574, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.1959 - acc: 0.9324 - val_loss: 0.1757 - val_acc: 0.9363
(180000,) (180000,)
161535 857
11169 6439

FA FR TA TR 0.00527735356421 0.634313948205 0.365686051795 0.994722646436

VALIDATION DATA
0.936333333333 0.175743340486
(18000,) (18000,)
16264 72
1074 590

FA FR TA TR 0.00440744368266 0.645432692308 0.354567307692 0.995592556317
0.175743340486  - val loss
0.178184453415  - final_loss
Validation Loss decreased. Great work



10  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.17574 to 0.17459, saving model to ./test/cnn/test-weights-0.17459.h5
Epoch 00000: val_loss improved from 0.17574 to 0.17459, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.1951 - acc: 0.9327 - val_loss: 0.1746 - val_acc: 0.9403
(180000,) (180000,)
160844 1548
9743 7865

FA FR TA TR 0.00953248928519 0.553328032712 0.446671967288 0.990467510715

VALIDATION DATA
0.940333333333 0.174592706925
(18000,) (18000,)
16209 127
947 717

FA FR TA TR 0.00777424094025 0.569110576923 0.430889423077 0.99222575906
0.174592706925  - val loss
0.175743340486  - final_loss
Validation Loss decreased. Great work



11  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1932 - acc: 0.9330 - val_loss: 0.1761 - val_acc: 0.9363
(180000,) (180000,)
161337 1055
10556 7052

FA FR TA TR 0.00649662544953 0.599500227169 0.400499772831 0.99350337455

VALIDATION DATA
0.936277777778 0.176068638368
(18000,) (18000,)
16262 74
1073 591

FA FR TA TR 0.00452987267385 0.644831730769 0.355168269231 0.995470127326
0.176068638368  - val loss
0.174592706925  - final_loss
Inside Plateau  1



11  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.17459 to 0.17281, saving model to ./test/cnn/test-weights-0.17281.h5
Epoch 00000: val_loss improved from 0.17459 to 0.17281, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.1922 - acc: 0.9333 - val_loss: 0.1728 - val_acc: 0.9374
(180000,) (180000,)
161434 958
10623 6985

FA FR TA TR 0.0058993053845 0.603305315766 0.396694684234 0.994100694615

VALIDATION DATA
0.937444444444 0.172813195656
(18000,) (18000,)
16265 71
1055 609

FA FR TA TR 0.00434622918707 0.634014423077 0.365985576923 0.995653770813
0.172813195656  - val loss
0.174592706925  - final_loss
Validation Loss decreased. Great work



12  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.17281 to 0.17034, saving model to ./test/cnn/test-weights-0.17034.h5
Epoch 00000: val_loss improved from 0.17281 to 0.17034, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.1904 - acc: 0.9340 - val_loss: 0.1703 - val_acc: 0.9440
(180000,) (180000,)
160515 1877
9032 8576

FA FR TA TR 0.0115584511552 0.5129486597 0.4870513403 0.988441548845

VALIDATION DATA
0.944 0.170335231066
(18000,) (18000,)
16190 146
862 802

FA FR TA TR 0.00893731635651 0.518028846154 0.481971153846 0.991062683643
0.170335231066  - val loss
0.172813195656  - final_loss
Validation Loss decreased. Great work



13  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1879 - acc: 0.9350 - val_loss: 0.1732 - val_acc: 0.9356
(180000,) (180000,)
161637 755
10999 6609

FA FR TA TR 0.00464924380511 0.624659245797 0.375340754203 0.995350756195

VALIDATION DATA
0.935611111111 0.173190926479
(18000,) (18000,)
16273 63
1096 568

FA FR TA TR 0.00385651322233 0.658653846154 0.341346153846 0.996143486778
0.173190926479  - val loss
0.170335231066  - final_loss
Inside Plateau  1



13  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.17034 to 0.16412, saving model to ./test/cnn/test-weights-0.16412.h5
Epoch 00000: val_loss improved from 0.17034 to 0.16412, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.1863 - acc: 0.9352 - val_loss: 0.1641 - val_acc: 0.9402
(180000,) (180000,)
161216 1176
9906 7702

FA FR TA TR 0.00724173604611 0.562585188551 0.437414811449 0.992758263954

VALIDATION DATA
0.940166666667 0.164116420855
(18000,) (18000,)
16253 83
994 670

FA FR TA TR 0.00508080313418 0.597355769231 0.402644230769 0.994919196866
0.164116420855  - val loss
0.170335231066  - final_loss
Validation Loss decreased. Great work



14  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1841 - acc: 0.9359 - val_loss: 0.1792 - val_acc: 0.9346
(180000,) (180000,)
161779 613
11569 6039

FA FR TA TR 0.00377481649342 0.657030895048 0.342969104952 0.996225183507

VALIDATION DATA
0.934555555556 0.179153087215
(18000,) (18000,)
16293 43
1135 529

FA FR TA TR 0.00263222331048 0.682091346154 0.317908653846 0.99736777669
0.179153087215  - val loss
0.164116420855  - final_loss
Inside Plateau  1



14  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1831 - acc: 0.9365 - val_loss: 0.1744 - val_acc: 0.9352
(180000,) (180000,)
161793 599
11513 6095

FA FR TA TR 0.00368860535002 0.65385052249 0.34614947751 0.99631139465

VALIDATION DATA
0.935222222222 0.174398928093
(18000,) (18000,)
16290 46
1120 544

FA FR TA TR 0.00281586679726 0.673076923077 0.326923076923 0.997184133203
0.174398928093  - val loss
0.164116420855  - final_loss
Inside Plateau  2



14  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.16412 to 0.16120, saving model to ./test/cnn/test-weights-0.16120.h5
Epoch 00000: val_loss improved from 0.16412 to 0.16120, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.1813 - acc: 0.9366 - val_loss: 0.1612 - val_acc: 0.9454
(180000,) (180000,)
160689 1703
8896 8712

FA FR TA TR 0.0104869698015 0.505224897774 0.494775102226 0.989513030199

VALIDATION DATA
0.945388888889 0.161199446221
(18000,) (18000,)
16192 144
839 825

FA FR TA TR 0.00881488736533 0.504206730769 0.495793269231 0.991185112635
0.161199446221  - val loss
0.164116420855  - final_loss
Validation Loss decreased. Great work



15  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1787 - acc: 0.9379 - val_loss: 0.1639 - val_acc: 0.9377
(180000,) (180000,)
161641 751
10950 6658

FA FR TA TR 0.00462461204985 0.621876419809 0.378123580191 0.99537538795

VALIDATION DATA
0.937666666667 0.163871683432
(18000,) (18000,)
16277 59
1063 601

FA FR TA TR 0.00361165523996 0.638822115385 0.361177884615 0.99638834476
0.163871683432  - val loss
0.161199446221  - final_loss
Inside Plateau  1



15  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1770 - acc: 0.9386 - val_loss: 0.1714 - val_acc: 0.9361
(180000,) (180000,)
161722 670
11036 6572

FA FR TA TR 0.00412581900586 0.62676056338 0.37323943662 0.995874180994

VALIDATION DATA
0.936111111111 0.171413328994
(18000,) (18000,)
16289 47
1103 561

FA FR TA TR 0.00287708129285 0.662860576923 0.337139423077 0.997122918707
0.171413328994  - val loss
0.161199446221  - final_loss
Inside Plateau  2



15  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.16120 to 0.15866, saving model to ./test/cnn/test-weights-0.15866.h5
Epoch 00000: val_loss improved from 0.16120 to 0.15866, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.1758 - acc: 0.9387 - val_loss: 0.1587 - val_acc: 0.9393
(180000,) (180000,)
161374 1018
9877 7731

FA FR TA TR 0.00626878171338 0.560938209905 0.439061790095 0.993731218287

VALIDATION DATA
0.939333333333 0.158657759756
(18000,) (18000,)
16257 79
1013 651

FA FR TA TR 0.00483594515181 0.608774038462 0.391225961538 0.995164054848
0.158657759756  - val loss
0.161199446221  - final_loss
Validation Loss decreased. Great work



16  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.15866 to 0.15233, saving model to ./test/cnn/test-weights-0.15233.h5
Epoch 00000: val_loss improved from 0.15866 to 0.15233, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.1738 - acc: 0.9392 - val_loss: 0.1523 - val_acc: 0.9434
(180000,) (180000,)
161180 1212
9324 8284

FA FR TA TR 0.00746342184344 0.529532030895 0.470467969105 0.992536578157

VALIDATION DATA
0.943388888889 0.152331861307
(18000,) (18000,)
16238 98
921 743

FA FR TA TR 0.00599902056807 0.553485576923 0.446514423077 0.994000979432
0.152331861307  - val loss
0.158657759756  - final_loss
Validation Loss decreased. Great work



17  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1724 - acc: 0.9397 - val_loss: 0.1536 - val_acc: 0.9497
(180000,) (180000,)
160198 2194
7737 9871

FA FR TA TR 0.0135105177595 0.439402544298 0.560597455702 0.986489482241

VALIDATION DATA
0.949722222222 0.153643648028
(18000,) (18000,)
16162 174
731 933

FA FR TA TR 0.0106513222331 0.439302884615 0.560697115385 0.989348677767
0.153643648028  - val loss
0.152331861307  - final_loss
Inside Plateau  1



17  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.15233 to 0.14999, saving model to ./test/cnn/test-weights-0.14999.h5
Epoch 00000: val_loss improved from 0.15233 to 0.14999, saving model to ./test/cnn/test_best_weights.h5
44s - loss: 0.1700 - acc: 0.9404 - val_loss: 0.1500 - val_acc: 0.9448
(180000,) (180000,)
161088 1304
8938 8670

FA FR TA TR 0.00802995221439 0.507610177192 0.492389822808 0.991970047786

VALIDATION DATA
0.944833333333 0.149990356237
(18000,) (18000,)
16240 96
897 767

FA FR TA TR 0.00587659157689 0.5390625 0.4609375 0.994123408423
0.149990356237  - val loss
0.152331861307  - final_loss
Validation Loss decreased. Great work



18  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1688 - acc: 0.9409 - val_loss: 0.1838 - val_acc: 0.9337
(180000,) (180000,)
161880 512
11489 6119

FA FR TA TR 0.00315286467314 0.652487505679 0.347512494321 0.996847135327

VALIDATION DATA
0.933722222222 0.183841338868
(18000,) (18000,)
16301 35
1158 506

FA FR TA TR 0.00214250734574 0.695913461538 0.304086538462 0.997857492654
0.183841338868  - val loss
0.149990356237  - final_loss
Inside Plateau  1



18  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1673 - acc: 0.9412 - val_loss: 0.1653 - val_acc: 0.9386
(180000,) (180000,)
161750 642
10732 6876

FA FR TA TR 0.00395339671905 0.60949568378 0.39050431622 0.996046603281

VALIDATION DATA
0.938555555556 0.165301001489
(18000,) (18000,)
16286 50
1056 608

FA FR TA TR 0.00306072477963 0.634615384615 0.365384615385 0.99693927522
0.165301001489  - val loss
0.149990356237  - final_loss
Inside Plateau  2



18  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1665 - acc: 0.9414 - val_loss: 0.5154 - val_acc: 0.7098
(180000,) (180000,)
116115 46277
1193 16415

FA FR TA TR 0.284970934529 0.0677532939573 0.932246706043 0.715029065471

VALIDATION DATA
0.709777777778 0.515408361594
(18000,) (18000,)
11201 5135
89 1575

FA FR TA TR 0.314336434868 0.0534855769231 0.946514423077 0.685663565132
0.515408361594  - val loss
0.149990356237  - final_loss
Inside Plateau  3



18  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
44s - loss: 0.1652 - acc: 0.9421 - val_loss: 0.1543 - val_acc: 0.9528
(180000,) (180000,)
159365 3027
6373 11235

FA FR TA TR 0.0186400807922 0.361937755566 0.638062244434 0.981359919208

VALIDATION DATA
0.952777777778 0.15426141917
(18000,) (18000,)
16113 223
627 1037

FA FR TA TR 0.0136508325171 0.376802884615 0.623197115385 0.986349167483
0.15426141917  - val loss
0.149990356237  - final_loss
Reducing the learning rate by half



18  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.14999 to 0.14781, saving model to ./test/cnn/test-weights-0.14781.h5
Epoch 00000: val_loss improved from 0.14999 to 0.14781, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1588 - acc: 0.9441 - val_loss: 0.1478 - val_acc: 0.9437
(180000,) (180000,)
161332 1060
9269 8339

FA FR TA TR 0.0065274151436 0.526408450704 0.473591549296 0.993472584856

VALIDATION DATA
0.943722222222 0.147807891467
(18000,) (18000,)
16252 84
929 735

FA FR TA TR 0.00514201762977 0.558293269231 0.441706730769 0.99485798237
0.147807891467  - val loss
0.149990356237  - final_loss
Validation Loss decreased. Great work



19  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.14781 to 0.14205, saving model to ./test/cnn/test-weights-0.14205.h5
Epoch 00000: val_loss improved from 0.14781 to 0.14205, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1580 - acc: 0.9439 - val_loss: 0.1421 - val_acc: 0.9468
(180000,) (180000,)
160830 1562
8205 9403

FA FR TA TR 0.00961870042859 0.465981372104 0.534018627896 0.990381299571

VALIDATION DATA
0.946777777778 0.142050311681
(18000,) (18000,)
16218 118
840 824

FA FR TA TR 0.00722331047992 0.504807692308 0.495192307692 0.99277668952
0.142050311681  - val loss
0.147807891467  - final_loss
Validation Loss decreased. Great work



20  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.14205 to 0.13908, saving model to ./test/cnn/test-weights-0.13908.h5
Epoch 00000: val_loss improved from 0.14205 to 0.13908, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1575 - acc: 0.9443 - val_loss: 0.1391 - val_acc: 0.9483
(180000,) (180000,)
160782 1610
8091 9517

FA FR TA TR 0.0099142814917 0.459507042254 0.540492957746 0.990085718508

VALIDATION DATA
0.948277777778 0.13908318352
(18000,) (18000,)
16224 112
819 845

FA FR TA TR 0.00685602350637 0.4921875 0.5078125 0.993143976494
0.13908318352  - val loss
0.142050311681  - final_loss
Validation Loss decreased. Great work



21  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13908 to 0.13837, saving model to ./test/cnn/test-weights-0.13837.h5
Epoch 00000: val_loss improved from 0.13908 to 0.13837, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1571 - acc: 0.9443 - val_loss: 0.1384 - val_acc: 0.9512
(180000,) (180000,)
160016 2376
6999 10609

FA FR TA TR 0.0146312626238 0.397489777374 0.602510222626 0.985368737376

VALIDATION DATA
0.951222222222 0.138373713142
(18000,) (18000,)
16178 158
720 944

FA FR TA TR 0.00967189030362 0.432692307692 0.567307692308 0.990328109696
0.138373713142  - val loss
0.13908318352  - final_loss
Validation Loss decreased. Great work



22  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13837 to 0.13739, saving model to ./test/cnn/test-weights-0.13739.h5
Epoch 00000: val_loss improved from 0.13837 to 0.13739, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1566 - acc: 0.9442 - val_loss: 0.1374 - val_acc: 0.9504
(180000,) (180000,)
160378 2014
7504 10104

FA FR TA TR 0.0124020887728 0.426169922762 0.573830077238 0.987597911227

VALIDATION DATA
0.950388888889 0.137389122688
(18000,) (18000,)
16209 127
766 898

FA FR TA TR 0.00777424094025 0.460336538462 0.539663461538 0.99222575906
0.137389122688  - val loss
0.138373713142  - final_loss
Validation Loss decreased. Great work



23  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1562 - acc: 0.9444 - val_loss: 0.1403 - val_acc: 0.9502
(180000,) (180000,)
160588 1804
7648 9960

FA FR TA TR 0.0111089216218 0.434348023626 0.565651976374 0.988891078378

VALIDATION DATA
0.950222222222 0.140250689844
(18000,) (18000,)
16211 125
771 893

FA FR TA TR 0.00765181194907 0.463341346154 0.536658653846 0.992348188051
0.140250689844  - val loss
0.137389122688  - final_loss
Inside Plateau  1



23  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1552 - acc: 0.9449 - val_loss: 0.1448 - val_acc: 0.9448
(180000,) (180000,)
161209 1183
8900 8708

FA FR TA TR 0.00728484161781 0.505452067242 0.494547932758 0.992715158382

VALIDATION DATA
0.944777777778 0.144782428889
(18000,) (18000,)
16248 88
906 758

FA FR TA TR 0.00538687561214 0.544471153846 0.455528846154 0.994613124388
0.144782428889  - val loss
0.137389122688  - final_loss
Inside Plateau  2



23  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1546 - acc: 0.9452 - val_loss: 0.1471 - val_acc: 0.9436
(180000,) (180000,)
161386 1006
9291 8317

FA FR TA TR 0.00619488644761 0.527657882781 0.472342117219 0.993805113552

VALIDATION DATA
0.943611111111 0.147092948
(18000,) (18000,)
16259 77
938 726

FA FR TA TR 0.00471351616063 0.563701923077 0.436298076923 0.995286483839
0.147092948  - val loss
0.137389122688  - final_loss
Inside Plateau  3



23  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1547 - acc: 0.9451 - val_loss: 0.1462 - val_acc: 0.9439
(180000,) (180000,)
161423 969
9329 8279

FA FR TA TR 0.00596704271146 0.529815992731 0.470184007269 0.994032957289

VALIDATION DATA
0.943944444444 0.146239326934
(18000,) (18000,)
16266 70
939 725

FA FR TA TR 0.00428501469148 0.564302884615 0.435697115385 0.995714985309
0.146239326934  - val loss
0.137389122688  - final_loss
Reducing the learning rate by half



23  iteration
0.0025  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1515 - acc: 0.9457 - val_loss: 0.1380 - val_acc: 0.9469
(180000,) (180000,)
160993 1399
8348 9260

FA FR TA TR 0.00861495640179 0.4741026806 0.5258973194 0.991385043598

VALIDATION DATA
0.946944444444 0.137992020567
(18000,) (18000,)
16230 106
849 815

FA FR TA TR 0.00648873653281 0.510216346154 0.489783653846 0.993511263467
0.137992020567  - val loss
0.137389122688  - final_loss
Inside Plateau  1



23  iteration
0.0025  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13739 to 0.13531, saving model to ./test/cnn/test-weights-0.13531.h5
Epoch 00000: val_loss improved from 0.13739 to 0.13531, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1512 - acc: 0.9456 - val_loss: 0.1353 - val_acc: 0.9508
(180000,) (180000,)
160567 1825
7645 9963

FA FR TA TR 0.0112382383369 0.434177646524 0.565822353476 0.988761761663

VALIDATION DATA
0.950777777778 0.135305520654
(18000,) (18000,)
16200 136
750 914

FA FR TA TR 0.00832517140059 0.450721153846 0.549278846154 0.991674828599
0.135305520654  - val loss
0.137389122688  - final_loss
Validation Loss decreased. Great work



24  iteration
0.0025  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1510 - acc: 0.9460 - val_loss: 0.1373 - val_acc: 0.9474
(180000,) (180000,)
160913 1479
8209 9399

FA FR TA TR 0.00910759150697 0.466208541572 0.533791458428 0.990892408493

VALIDATION DATA
0.947444444444 0.137273574938
(18000,) (18000,)
16234 102
844 820

FA FR TA TR 0.00624387855044 0.507211538462 0.492788461538 0.99375612145
0.137273574938  - val loss
0.135305520654  - final_loss
Inside Plateau  1



24  iteration
0.0025  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1513 - acc: 0.9460 - val_loss: 0.1354 - val_acc: 0.9512
(180000,) (180000,)
160413 1979
7311 10297

FA FR TA TR 0.0121865609143 0.415208995911 0.584791004089 0.987813439086

VALIDATION DATA
0.951222222222 0.135357309547
(18000,) (18000,)
16194 142
736 928

FA FR TA TR 0.00869245837414 0.442307692308 0.557692307692 0.991307541626
0.135357309547  - val loss
0.135305520654  - final_loss
Inside Plateau  2



24  iteration
0.0025  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1506 - acc: 0.9461 - val_loss: 0.1379 - val_acc: 0.9532
(180000,) (180000,)
159862 2530
6578 11030

FA FR TA TR 0.0155795852012 0.373580190822 0.626419809178 0.984420414799

VALIDATION DATA
0.953222222222 0.137878079315
(18000,) (18000,)
16153 183
659 1005

FA FR TA TR 0.0112022526934 0.396033653846 0.603966346154 0.988797747307
0.137878079315  - val loss
0.135305520654  - final_loss
Inside Plateau  3



24  iteration
0.0025  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1508 - acc: 0.9461 - val_loss: 0.1377 - val_acc: 0.9470
(180000,) (180000,)
161006 1386
8330 9278

FA FR TA TR 0.0085349031972 0.473080417992 0.526919582008 0.991465096803

VALIDATION DATA
0.947 0.137716986342
(18000,) (18000,)
16226 110
844 820

FA FR TA TR 0.00673359451518 0.507211538462 0.492788461538 0.993266405485
0.137716986342  - val loss
0.135305520654  - final_loss
Reducing the learning rate by half



24  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1498 - acc: 0.9465 - val_loss: 0.1367 - val_acc: 0.9472
(180000,) (180000,)
160983 1409
8342 9266

FA FR TA TR 0.00867653578994 0.473761926397 0.526238073603 0.99132346421

VALIDATION DATA
0.947222222222 0.136735613926
(18000,) (18000,)
16233 103
847 817

FA FR TA TR 0.00630509304603 0.509014423077 0.490985576923 0.993694906954
0.136735613926  - val loss
0.135305520654  - final_loss
Inside Plateau  1



24  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13531 to 0.13515, saving model to ./test/cnn/test-weights-0.13515.h5
Epoch 00000: val_loss improved from 0.13531 to 0.13515, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1490 - acc: 0.9467 - val_loss: 0.1352 - val_acc: 0.9522
(180000,) (180000,)
160112 2280
6924 10684

FA FR TA TR 0.0140401004976 0.393230349841 0.606769650159 0.985959899502

VALIDATION DATA
0.952166666667 0.135151099361
(18000,) (18000,)
16171 165
696 968

FA FR TA TR 0.0101003917728 0.418269230769 0.581730769231 0.989899608227
0.135151099361  - val loss
0.135305520654  - final_loss
Validation Loss decreased. Great work



25  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13515 to 0.13407, saving model to ./test/cnn/test-weights-0.13407.h5
Epoch 00000: val_loss improved from 0.13515 to 0.13407, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1491 - acc: 0.9465 - val_loss: 0.1341 - val_acc: 0.9508
(180000,) (180000,)
160629 1763
7696 9912

FA FR TA TR 0.0108564461304 0.437074057247 0.562925942753 0.98914355387

VALIDATION DATA
0.950777777778 0.13407150858
(18000,) (18000,)
16209 127
759 905

FA FR TA TR 0.00777424094025 0.456129807692 0.543870192308 0.99222575906
0.13407150858  - val loss
0.135151099361  - final_loss
Validation Loss decreased. Great work



26  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1491 - acc: 0.9462 - val_loss: 0.1399 - val_acc: 0.9463
(180000,) (180000,)
161169 1223
8657 8951

FA FR TA TR 0.0075311591704 0.491651522035 0.508348477965 0.99246884083

VALIDATION DATA
0.946277777778 0.139902630124
(18000,) (18000,)
16245 91
876 788

FA FR TA TR 0.00557051909892 0.526442307692 0.473557692308 0.994429480901
0.139902630124  - val loss
0.13407150858  - final_loss
Inside Plateau  1



26  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13407 to 0.13393, saving model to ./test/cnn/test-weights-0.13393.h5
Epoch 00000: val_loss improved from 0.13407 to 0.13393, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1487 - acc: 0.9464 - val_loss: 0.1339 - val_acc: 0.9517
(180000,) (180000,)
160209 2183
7074 10534

FA FR TA TR 0.0134427804325 0.401749204907 0.598250795093 0.986557219567

VALIDATION DATA
0.951666666667 0.133930156877
(18000,) (18000,)
16181 155
715 949

FA FR TA TR 0.00948824681685 0.4296875 0.5703125 0.990511753183
0.133930156877  - val loss
0.13407150858  - final_loss
Validation Loss decreased. Great work



27  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1491 - acc: 0.9466 - val_loss: 0.1349 - val_acc: 0.9523
(180000,) (180000,)
160118 2274
6966 10642

FA FR TA TR 0.0140031528647 0.395615629259 0.604384370741 0.985996847135

VALIDATION DATA
0.952277777778 0.134876025558
(18000,) (18000,)
16171 165
694 970

FA FR TA TR 0.0101003917728 0.417067307692 0.582932692308 0.989899608227
0.134876025558  - val loss
0.133930156877  - final_loss
Inside Plateau  1



27  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1487 - acc: 0.9465 - val_loss: 0.1358 - val_acc: 0.9482
(180000,) (180000,)
160929 1463
8197 9411

FA FR TA TR 0.00900906448594 0.465527033167 0.534472966833 0.990990935514

VALIDATION DATA
0.948166666667 0.135753861696
(18000,) (18000,)
16225 111
822 842

FA FR TA TR 0.00679480901077 0.493990384615 0.506009615385 0.993205190989
0.135753861696  - val loss
0.133930156877  - final_loss
Inside Plateau  2



27  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1485 - acc: 0.9466 - val_loss: 0.1345 - val_acc: 0.9500
(180000,) (180000,)
160813 1579
8014 9594

FA FR TA TR 0.00972338538844 0.455134029986 0.544865970014 0.990276614612

VALIDATION DATA
0.95 0.134508339246
(18000,) (18000,)
16220 116
784 880

FA FR TA TR 0.00710088148874 0.471153846154 0.528846153846 0.992899118511
0.134508339246  - val loss
0.133930156877  - final_loss
Inside Plateau  3



27  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1486 - acc: 0.9466 - val_loss: 0.1353 - val_acc: 0.9489
(180000,) (180000,)
160878 1514
8086 9522

FA FR TA TR 0.00932311936549 0.459223080418 0.540776919582 0.990676880635

VALIDATION DATA
0.948888888889 0.135279642224
(18000,) (18000,)
16224 112
808 856

FA FR TA TR 0.00685602350637 0.485576923077 0.514423076923 0.993143976494
0.135279642224  - val loss
0.133930156877  - final_loss
Reducing the learning rate by half



27  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1483 - acc: 0.9467 - val_loss: 0.1361 - val_acc: 0.9476
(180000,) (180000,)
160970 1422
8248 9360

FA FR TA TR 0.00875658899453 0.468423443889 0.531576556111 0.991243411005

VALIDATION DATA
0.947611111111 0.136119336834
(18000,) (18000,)
16227 109
834 830

FA FR TA TR 0.00667238001959 0.501201923077 0.498798076923 0.99332761998
0.136119336834  - val loss
0.133930156877  - final_loss
Inside Plateau  1



27  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13393 to 0.13359, saving model to ./test/cnn/test-weights-0.13359.h5
Epoch 00000: val_loss improved from 0.13393 to 0.13359, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1481 - acc: 0.9470 - val_loss: 0.1336 - val_acc: 0.9508
(180000,) (180000,)
160692 1700
7764 9844

FA FR TA TR 0.010468495985 0.44093593821 0.55906406179 0.989531504015

VALIDATION DATA
0.950833333333 0.133592724194
(18000,) (18000,)
16215 121
764 900

FA FR TA TR 0.0074069539667 0.459134615385 0.540865384615 0.992593046033
0.133592724194  - val loss
0.133930156877  - final_loss
Validation Loss decreased. Great work



28  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1479 - acc: 0.9466 - val_loss: 0.1337 - val_acc: 0.9508
(180000,) (180000,)
160720 1672
7818 9790

FA FR TA TR 0.0102960736982 0.444002726034 0.555997273966 0.989703926302

VALIDATION DATA
0.950777777778 0.133743509968
(18000,) (18000,)
16214 122
764 900

FA FR TA TR 0.00746816846229 0.459134615385 0.540865384615 0.992531831538
0.133743509968  - val loss
0.133592724194  - final_loss
Inside Plateau  1



28  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1476 - acc: 0.9466 - val_loss: 0.1336 - val_acc: 0.9509
(180000,) (180000,)
160661 1731
7695 9913

FA FR TA TR 0.0106593920883 0.43701726488 0.56298273512 0.989340607912

VALIDATION DATA
0.950888888889 0.133599854277
(18000,) (18000,)
16212 124
760 904

FA FR TA TR 0.00759059745348 0.456730769231 0.543269230769 0.992409402547
0.133599854277  - val loss
0.133592724194  - final_loss
Inside Plateau  2



28  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1478 - acc: 0.9469 - val_loss: 0.1348 - val_acc: 0.9496
(180000,) (180000,)
160854 1538
8035 9573

FA FR TA TR 0.00947090989704 0.456326669696 0.543673330304 0.990529090103

VALIDATION DATA
0.949555555556 0.134843425469
(18000,) (18000,)
16222 114
794 870

FA FR TA TR 0.00697845249755 0.477163461538 0.522836538462 0.993021547502
0.134843425469  - val loss
0.133592724194  - final_loss
Inside Plateau  3



28  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13359 to 0.13309, saving model to ./test/cnn/test-weights-0.13309.h5
Epoch 00000: val_loss improved from 0.13359 to 0.13309, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1470 - acc: 0.9474 - val_loss: 0.1331 - val_acc: 0.9521
(180000,) (180000,)
160232 2160
7049 10559

FA FR TA TR 0.0133011478398 0.400329395729 0.599670604271 0.98669885216

VALIDATION DATA
0.952055555556 0.133088201404
(18000,) (18000,)
16177 159
704 960

FA FR TA TR 0.00973310479922 0.423076923077 0.576923076923 0.990266895201
0.133088201404  - val loss
0.133592724194  - final_loss
Validation Loss decreased. Great work



29  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1479 - acc: 0.9469 - val_loss: 0.1339 - val_acc: 0.9528
(180000,) (180000,)
160155 2237
6949 10659

FA FR TA TR 0.0137753091285 0.394650159019 0.605349840981 0.986224690871

VALIDATION DATA
0.952777777778 0.133917881022
(18000,) (18000,)
16171 165
685 979

FA FR TA TR 0.0101003917728 0.411658653846 0.588341346154 0.989899608227
0.133917881022  - val loss
0.133088201404  - final_loss
Inside Plateau  1



29  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1475 - acc: 0.9471 - val_loss: 0.1344 - val_acc: 0.9498
(180000,) (180000,)
160819 1573
7952 9656

FA FR TA TR 0.00968643775555 0.451612903226 0.548387096774 0.990313562244

VALIDATION DATA
0.949777777778 0.13435310582
(18000,) (18000,)
16222 114
790 874

FA FR TA TR 0.00697845249755 0.474759615385 0.525240384615 0.993021547502
0.13435310582  - val loss
0.133088201404  - final_loss
Inside Plateau  2



29  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1480 - acc: 0.9465 - val_loss: 0.1331 - val_acc: 0.9518
(180000,) (180000,)
160407 1985
7274 10334

FA FR TA TR 0.0122235085472 0.413107678328 0.586892321672 0.987776491453

VALIDATION DATA
0.951777777778 0.133105588986
(18000,) (18000,)
16192 144
724 940

FA FR TA TR 0.00881488736533 0.435096153846 0.564903846154 0.991185112635
0.133105588986  - val loss
0.133088201404  - final_loss
Inside Plateau  3



29  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13309 to 0.13272, saving model to ./test/cnn/test-weights-0.13272.h5
Epoch 00000: val_loss improved from 0.13309 to 0.13272, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1477 - acc: 0.9469 - val_loss: 0.1327 - val_acc: 0.9510
(180000,) (180000,)
160498 1894
7429 10179

FA FR TA TR 0.0116631361151 0.421910495229 0.578089504771 0.988336863885

VALIDATION DATA
0.951 0.132721894546
(18000,) (18000,)
16198 138
744 920

FA FR TA TR 0.00844760039177 0.447115384615 0.552884615385 0.991552399608
0.132721894546  - val loss
0.133088201404  - final_loss
Validation Loss decreased. Great work



30  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1477 - acc: 0.9469 - val_loss: 0.1335 - val_acc: 0.9507
(180000,) (180000,)
160738 1654
7835 9773

FA FR TA TR 0.0101852307995 0.444968196274 0.555031803726 0.9898147692

VALIDATION DATA
0.950722222222 0.133472498993
(18000,) (18000,)
16217 119
768 896

FA FR TA TR 0.00728452497551 0.461538461538 0.538461538462 0.992715475024
0.133472498993  - val loss
0.132721894546  - final_loss
Inside Plateau  1



30  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1477 - acc: 0.9466 - val_loss: 0.1331 - val_acc: 0.9509
(180000,) (180000,)
160742 1650
7833 9775

FA FR TA TR 0.0101605990443 0.44485461154 0.55514538846 0.989839400956

VALIDATION DATA
0.950944444444 0.133127580769
(18000,) (18000,)
16217 119
764 900

FA FR TA TR 0.00728452497551 0.459134615385 0.540865384615 0.992715475024
0.133127580769  - val loss
0.132721894546  - final_loss
Inside Plateau  2



30  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1475 - acc: 0.9470 - val_loss: 0.1354 - val_acc: 0.9483
(180000,) (180000,)
160943 1449
8169 9439

FA FR TA TR 0.00892285334253 0.463936846888 0.536063153112 0.991077146657

VALIDATION DATA
0.948277777778 0.135400218225
(18000,) (18000,)
16225 111
820 844

FA FR TA TR 0.00679480901077 0.492788461538 0.507211538462 0.993205190989
0.135400218225  - val loss
0.132721894546  - final_loss
Inside Plateau  3



30  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1474 - acc: 0.9466 - val_loss: 0.1331 - val_acc: 0.9508
(180000,) (180000,)
160690 1702
7728 9880

FA FR TA TR 0.0104808118627 0.438891412994 0.561108587006 0.989519188137

VALIDATION DATA
0.950833333333 0.133130112946
(18000,) (18000,)
16211 125
760 904

FA FR TA TR 0.00765181194907 0.456730769231 0.543269230769 0.992348188051
0.133130112946  - val loss
0.132721894546  - final_loss
Reducing the learning rate by half



30  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1471 - acc: 0.9470 - val_loss: 0.1335 - val_acc: 0.9507
(180000,) (180000,)
160754 1638
7837 9771

FA FR TA TR 0.0100867037785 0.445081781009 0.554918218991 0.989913296221

VALIDATION DATA
0.950722222222 0.133472588453
(18000,) (18000,)
16219 117
770 894

FA FR TA TR 0.00716209598433 0.462740384615 0.537259615385 0.992837904016
0.133472588453  - val loss
0.132721894546  - final_loss
Inside Plateau  1



30  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13272 to 0.13271, saving model to ./test/cnn/test-weights-0.13271.h5
Epoch 00000: val_loss improved from 0.13272 to 0.13271, saving model to ./test/cnn/test_best_weights.h5
45s - loss: 0.1472 - acc: 0.9468 - val_loss: 0.1327 - val_acc: 0.9512
(180000,) (180000,)
160520 1872
7454 10154

FA FR TA TR 0.0115276614612 0.423330304407 0.576669695593 0.988472338539

VALIDATION DATA
0.951166666667 0.13270779508
(18000,) (18000,)
16203 133
746 918

FA FR TA TR 0.00814152791381 0.448317307692 0.551682692308 0.991858472086
0.13270779508  - val loss
0.132721894546  - final_loss
Validation Loss decreased. Great work



31  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1470 - acc: 0.9470 - val_loss: 0.1344 - val_acc: 0.9494
(180000,) (180000,)
160883 1509
8088 9520

FA FR TA TR 0.00929232967141 0.459336665152 0.540663334848 0.990707670329

VALIDATION DATA
0.949444444444 0.134353518433
(18000,) (18000,)
16225 111
799 865

FA FR TA TR 0.00679480901077 0.480168269231 0.519831730769 0.993205190989
0.134353518433  - val loss
0.13270779508  - final_loss
Inside Plateau  1



31  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13271 to 0.13267, saving model to ./test/cnn/test-weights-0.13267.h5
Epoch 00000: val_loss improved from 0.13271 to 0.13267, saving model to ./test/cnn/test_best_weights.h5
46s - loss: 0.1468 - acc: 0.9470 - val_loss: 0.1327 - val_acc: 0.9509
(180000,) (180000,)
160615 1777
7577 10031

FA FR TA TR 0.0109426572738 0.430315765561 0.569684234439 0.989057342726

VALIDATION DATA
0.950888888889 0.132668294791
(18000,) (18000,)
16207 129
755 909

FA FR TA TR 0.00789666993144 0.453725961538 0.546274038462 0.992103330069
0.132668294791  - val loss
0.13270779508  - final_loss
Validation Loss decreased. Great work



32  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13267 to 0.13266, saving model to ./test/cnn/test-weights-0.13266.h5
Epoch 00000: val_loss improved from 0.13267 to 0.13266, saving model to ./test/cnn/test_best_weights.h5
46s - loss: 0.1466 - acc: 0.9467 - val_loss: 0.1327 - val_acc: 0.9509
(180000,) (180000,)
160648 1744
7650 9958

FA FR TA TR 0.0107394452929 0.43446160836 0.56553839164 0.989260554707

VALIDATION DATA
0.950888888889 0.132656447646
(18000,) (18000,)
16204 132
752 912

FA FR TA TR 0.00808031341822 0.451923076923 0.548076923077 0.991919686582
0.132656447646  - val loss
0.132668294791  - final_loss
Validation Loss decreased. Great work



33  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1469 - acc: 0.9470 - val_loss: 0.1337 - val_acc: 0.9502
(180000,) (180000,)
160836 1556
7989 9619

FA FR TA TR 0.0095817527957 0.453714220809 0.546285779191 0.990418247204

VALIDATION DATA
0.950166666667 0.133650707626
(18000,) (18000,)
16220 116
781 883

FA FR TA TR 0.00710088148874 0.469350961538 0.530649038462 0.992899118511
0.133650707626  - val loss
0.132656447646  - final_loss
Inside Plateau  1



33  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13266 to 0.13244, saving model to ./test/cnn/test-weights-0.13244.h5
Epoch 00000: val_loss improved from 0.13266 to 0.13244, saving model to ./test/cnn/test_best_weights.h5
46s - loss: 0.1470 - acc: 0.9469 - val_loss: 0.1324 - val_acc: 0.9514
(180000,) (180000,)
160533 1859
7462 10146

FA FR TA TR 0.0114476082566 0.423784643344 0.576215356656 0.988552391743

VALIDATION DATA
0.951444444444 0.132443003313
(18000,) (18000,)
16200 136
738 926

FA FR TA TR 0.00832517140059 0.443509615385 0.556490384615 0.991674828599
0.132443003313  - val loss
0.132656447646  - final_loss
Validation Loss decreased. Great work



34  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1472 - acc: 0.9469 - val_loss: 0.1342 - val_acc: 0.9492
(180000,) (180000,)
160880 1512
8061 9547

FA FR TA TR 0.00931080348786 0.45780327124 0.54219672876 0.990689196512

VALIDATION DATA
0.949222222222 0.134206473764
(18000,) (18000,)
16223 113
801 863

FA FR TA TR 0.00691723800196 0.481370192308 0.518629807692 0.993082761998
0.134206473764  - val loss
0.132443003313  - final_loss
Inside Plateau  1



34  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13244 to 0.13241, saving model to ./test/cnn/test-weights-0.13241.h5
Epoch 00000: val_loss improved from 0.13244 to 0.13241, saving model to ./test/cnn/test_best_weights.h5
46s - loss: 0.1467 - acc: 0.9474 - val_loss: 0.1324 - val_acc: 0.9512
(180000,) (180000,)
160520 1872
7444 10164

FA FR TA TR 0.0115276614612 0.422762380736 0.577237619264 0.988472338539

VALIDATION DATA
0.951222222222 0.1324134554
(18000,) (18000,)
16200 136
742 922

FA FR TA TR 0.00832517140059 0.445913461538 0.554086538462 0.991674828599
0.1324134554  - val loss
0.132443003313  - final_loss
Validation Loss decreased. Great work



35  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1469 - acc: 0.9467 - val_loss: 0.1330 - val_acc: 0.9509
(180000,) (180000,)
160731 1661
7806 9802

FA FR TA TR 0.0102283363712 0.443321217628 0.556678782372 0.989771663629

VALIDATION DATA
0.950888888889 0.132952228056
(18000,) (18000,)
16217 119
765 899

FA FR TA TR 0.00728452497551 0.459735576923 0.540264423077 0.992715475024
0.132952228056  - val loss
0.1324134554  - final_loss
Inside Plateau  1



35  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1468 - acc: 0.9473 - val_loss: 0.1334 - val_acc: 0.9506
(180000,) (180000,)
160757 1635
7841 9767

FA FR TA TR 0.0100682299621 0.445308950477 0.554691049523 0.989931770038

VALIDATION DATA
0.950555555556 0.133368126618
(18000,) (18000,)
16217 119
771 893

FA FR TA TR 0.00728452497551 0.463341346154 0.536658653846 0.992715475024
0.133368126618  - val loss
0.1324134554  - final_loss
Inside Plateau  2



35  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
45s - loss: 0.1468 - acc: 0.9472 - val_loss: 0.1328 - val_acc: 0.9507
(180000,) (180000,)
160727 1665
7780 9828

FA FR TA TR 0.0102529681265 0.441844616084 0.558155383916 0.989747031873

VALIDATION DATA
0.950722222222 0.132836209824
(18000,) (18000,)
16215 121
766 898

FA FR TA TR 0.0074069539667 0.460336538462 0.539663461538 0.992593046033
0.132836209824  - val loss
0.1324134554  - final_loss
Inside Plateau  3



35  iteration
0.0003125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1464 - acc: 0.9471 - val_loss: 0.1342 - val_acc: 0.9493
(180000,) (180000,)
160892 1500
8076 9532

FA FR TA TR 0.00923690822208 0.458655156747 0.541344843253 0.990763091778

VALIDATION DATA
0.949277777778 0.13416203528
(18000,) (18000,)
16225 111
802 862

FA FR TA TR 0.00679480901077 0.481971153846 0.518028846154 0.993205190989
0.13416203528  - val loss
0.1324134554  - final_loss
Reducing the learning rate by half



35  iteration
0.00015625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1466 - acc: 0.9471 - val_loss: 0.1332 - val_acc: 0.9506
(180000,) (180000,)
160777 1615
7876 9732

FA FR TA TR 0.00994507118577 0.447296683326 0.552703316674 0.990054928814

VALIDATION DATA
0.950555555556 0.133238347822
(18000,) (18000,)
16219 117
773 891

FA FR TA TR 0.00716209598433 0.464543269231 0.535456730769 0.992837904016
0.133238347822  - val loss
0.1324134554  - final_loss
Inside Plateau  1



35  iteration
0.00015625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1470 - acc: 0.9471 - val_loss: 0.1326 - val_acc: 0.9508
(180000,) (180000,)
160627 1765
7609 9999

FA FR TA TR 0.010868762008 0.432133121308 0.567866878692 0.989131237992

VALIDATION DATA
0.950777777778 0.132600054539
(18000,) (18000,)
16205 131
755 909

FA FR TA TR 0.00801909892262 0.453725961538 0.546274038462 0.991980901077
0.132600054539  - val loss
0.1324134554  - final_loss
Inside Plateau  2



35  iteration
0.00015625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1464 - acc: 0.9473 - val_loss: 0.1325 - val_acc: 0.9508
(180000,) (180000,)
160600 1792
7566 10042

FA FR TA TR 0.011035026356 0.429691049523 0.570308950477 0.988964973644

VALIDATION DATA
0.950777777778 0.132494739936
(18000,) (18000,)
16204 132
754 910

FA FR TA TR 0.00808031341822 0.453125 0.546875 0.991919686582
0.132494739936  - val loss
0.1324134554  - final_loss
Inside Plateau  3



35  iteration
0.00015625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1468 - acc: 0.9470 - val_loss: 0.1326 - val_acc: 0.9511
(180000,) (180000,)
160649 1743
7645 9963

FA FR TA TR 0.0107332873541 0.434177646524 0.565822353476 0.989266712646

VALIDATION DATA
0.951055555556 0.132597043607
(18000,) (18000,)
16212 124
757 907

FA FR TA TR 0.00759059745348 0.454927884615 0.545072115385 0.992409402547
0.132597043607  - val loss
0.1324134554  - final_loss
Reducing the learning rate by half



35  iteration
7.8125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13241 to 0.13238, saving model to ./test/cnn/test-weights-0.13238.h5
Epoch 00000: val_loss improved from 0.13241 to 0.13238, saving model to ./test/cnn/test_best_weights.h5
46s - loss: 0.1466 - acc: 0.9472 - val_loss: 0.1324 - val_acc: 0.9509
(180000,) (180000,)
160575 1817
7530 10078

FA FR TA TR 0.0111889748263 0.427646524307 0.572353475693 0.988811025174

VALIDATION DATA
0.950888888889 0.132375485748
(18000,) (18000,)
16204 132
752 912

FA FR TA TR 0.00808031341822 0.451923076923 0.548076923077 0.991919686582
0.132375485748  - val loss
0.1324134554  - final_loss
Validation Loss decreased. Great work



36  iteration
7.8125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1461 - acc: 0.9474 - val_loss: 0.1324 - val_acc: 0.9508
(180000,) (180000,)
160580 1812
7535 10073

FA FR TA TR 0.0111581851323 0.427930486143 0.572069513857 0.988841814868

VALIDATION DATA
0.950777777778 0.13238812891
(18000,) (18000,)
16204 132
754 910

FA FR TA TR 0.00808031341822 0.453125 0.546875 0.991919686582
0.13238812891  - val loss
0.132375485748  - final_loss
Inside Plateau  1



36  iteration
7.8125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1460 - acc: 0.9474 - val_loss: 0.1325 - val_acc: 0.9508
(180000,) (180000,)
160627 1765
7611 9997

FA FR TA TR 0.010868762008 0.432246706043 0.567753293957 0.989131237992

VALIDATION DATA
0.950833333333 0.132512965884
(18000,) (18000,)
16207 129
756 908

FA FR TA TR 0.00789666993144 0.454326923077 0.545673076923 0.992103330069
0.132512965884  - val loss
0.132375485748  - final_loss
Inside Plateau  2



36  iteration
7.8125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13238 to 0.13234, saving model to ./test/cnn/test-weights-0.13234.h5
Epoch 00000: val_loss improved from 0.13238 to 0.13234, saving model to ./test/cnn/test_best_weights.h5
46s - loss: 0.1463 - acc: 0.9472 - val_loss: 0.1323 - val_acc: 0.9510
(180000,) (180000,)
160558 1834
7501 10107

FA FR TA TR 0.0112936597862 0.425999545661 0.574000454339 0.988706340214

VALIDATION DATA
0.951 0.132339904298
(18000,) (18000,)
16203 133
749 915

FA FR TA TR 0.00814152791381 0.450120192308 0.549879807692 0.991858472086
0.132339904298  - val loss
0.132375485748  - final_loss
Validation Loss decreased. Great work



37  iteration
7.8125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1466 - acc: 0.9471 - val_loss: 0.1328 - val_acc: 0.9510
(180000,) (180000,)
160707 1685
7737 9871

FA FR TA TR 0.0103761269028 0.439402544298 0.560597455702 0.989623873097

VALIDATION DATA
0.951 0.132772468636
(18000,) (18000,)
16216 120
762 902

FA FR TA TR 0.00734573947111 0.457932692308 0.542067307692 0.992654260529
0.132772468636  - val loss
0.132339904298  - final_loss
Inside Plateau  1



37  iteration
7.8125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1464 - acc: 0.9471 - val_loss: 0.1325 - val_acc: 0.9508
(180000,) (180000,)
160619 1773
7586 10022

FA FR TA TR 0.0109180255185 0.430826896865 0.569173103135 0.989081974482

VALIDATION DATA
0.950777777778 0.132458069119
(18000,) (18000,)
16205 131
755 909

FA FR TA TR 0.00801909892262 0.453725961538 0.546274038462 0.991980901077
0.132458069119  - val loss
0.132339904298  - final_loss
Inside Plateau  2



37  iteration
7.8125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1467 - acc: 0.9470 - val_loss: 0.1327 - val_acc: 0.9511
(180000,) (180000,)
160689 1703
7689 9919

FA FR TA TR 0.0104869698015 0.436676510677 0.563323489323 0.989513030199

VALIDATION DATA
0.951055555556 0.132660875701
(18000,) (18000,)
16214 122
759 905

FA FR TA TR 0.00746816846229 0.456129807692 0.543870192308 0.992531831538
0.132660875701  - val loss
0.132339904298  - final_loss
Inside Plateau  3



37  iteration
7.8125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1465 - acc: 0.9470 - val_loss: 0.1325 - val_acc: 0.9509
(180000,) (180000,)
160620 1772
7592 10016

FA FR TA TR 0.0109118675797 0.431167651068 0.568832348932 0.98908813242

VALIDATION DATA
0.950888888889 0.132492953456
(18000,) (18000,)
16205 131
753 911

FA FR TA TR 0.00801909892262 0.452524038462 0.547475961538 0.991980901077
0.132492953456  - val loss
0.132339904298  - final_loss
Reducing the learning rate by half



37  iteration
3.90625e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1466 - acc: 0.9468 - val_loss: 0.1324 - val_acc: 0.9510
(180000,) (180000,)
160572 1820
7523 10085

FA FR TA TR 0.0112074486428 0.427248977737 0.572751022263 0.988792551357

VALIDATION DATA
0.951 0.132351214839
(18000,) (18000,)
16204 132
750 914

FA FR TA TR 0.00808031341822 0.450721153846 0.549278846154 0.991919686582
0.132351214839  - val loss
0.132339904298  - final_loss
Inside Plateau  1



37  iteration
3.90625e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1465 - acc: 0.9470 - val_loss: 0.1327 - val_acc: 0.9510
(180000,) (180000,)
160687 1705
7687 9921

FA FR TA TR 0.0104992856791 0.436562925943 0.563437074057 0.989500714321

VALIDATION DATA
0.951 0.132691869126
(18000,) (18000,)
16214 122
760 904

FA FR TA TR 0.00746816846229 0.456730769231 0.543269230769 0.992531831538
0.132691869126  - val loss
0.132339904298  - final_loss
Inside Plateau  2



37  iteration
3.90625e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.13234 to 0.13225, saving model to ./test/cnn/test-weights-0.13225.h5
Epoch 00000: val_loss improved from 0.13234 to 0.13225, saving model to ./test/cnn/test_best_weights.h5
46s - loss: 0.1462 - acc: 0.9471 - val_loss: 0.1323 - val_acc: 0.9512
(180000,) (180000,)
160503 1889
7421 10187

FA FR TA TR 0.011632346421 0.421456156293 0.578543843707 0.988367653579

VALIDATION DATA
0.951166666667 0.132250548498
(18000,) (18000,)
16198 138
741 923

FA FR TA TR 0.00844760039177 0.4453125 0.5546875 0.991552399608
0.132250548498  - val loss
0.132339904298  - final_loss
Validation Loss decreased. Great work



38  iteration
3.90625e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1465 - acc: 0.9471 - val_loss: 0.1325 - val_acc: 0.9508
(180000,) (180000,)
160637 1755
7605 10003

FA FR TA TR 0.0108071826198 0.43190595184 0.56809404816 0.98919281738

VALIDATION DATA
0.950833333333 0.132511812088
(18000,) (18000,)
16207 129
756 908

FA FR TA TR 0.00789666993144 0.454326923077 0.545673076923 0.992103330069
0.132511812088  - val loss
0.132250548498  - final_loss
Inside Plateau  1



38  iteration
3.90625e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1466 - acc: 0.9472 - val_loss: 0.1327 - val_acc: 0.9510
(180000,) (180000,)
160690 1702
7688 9920

FA FR TA TR 0.0104808118627 0.43661971831 0.56338028169 0.989519188137

VALIDATION DATA
0.951 0.132689977553
(18000,) (18000,)
16214 122
760 904

FA FR TA TR 0.00746816846229 0.456730769231 0.543269230769 0.992531831538
0.132689977553  - val loss
0.132250548498  - final_loss
Inside Plateau  2



38  iteration
3.90625e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1464 - acc: 0.9470 - val_loss: 0.1323 - val_acc: 0.9510
(180000,) (180000,)
160566 1826
7523 10085

FA FR TA TR 0.0112443962757 0.427248977737 0.572751022263 0.988755603724

VALIDATION DATA
0.951 0.132326048219
(18000,) (18000,)
16204 132
750 914

FA FR TA TR 0.00808031341822 0.450721153846 0.549278846154 0.991919686582
0.132326048219  - val loss
0.132250548498  - final_loss
Inside Plateau  3



38  iteration
3.90625e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1465 - acc: 0.9472 - val_loss: 0.1326 - val_acc: 0.9511
(180000,) (180000,)
160674 1718
7675 9933

FA FR TA TR 0.0105793388837 0.435881417537 0.564118582463 0.989420661116

VALIDATION DATA
0.951055555556 0.132569017063
(18000,) (18000,)
16213 123
758 906

FA FR TA TR 0.00752938295788 0.455528846154 0.544471153846 0.992470617042
0.132569017063  - val loss
0.132250548498  - final_loss
Reducing the learning rate by half



38  iteration
1.953125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1463 - acc: 0.9471 - val_loss: 0.1325 - val_acc: 0.9508
(180000,) (180000,)
160639 1753
7613 9995

FA FR TA TR 0.0107948667422 0.432360290777 0.567639709223 0.989205133258

VALIDATION DATA
0.950833333333 0.132457183792
(18000,) (18000,)
16206 130
755 909

FA FR TA TR 0.00795788442703 0.453725961538 0.546274038462 0.992042115573
0.132457183792  - val loss
0.132250548498  - final_loss
Inside Plateau  1



38  iteration
1.953125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1466 - acc: 0.9470 - val_loss: 0.1325 - val_acc: 0.9509
(180000,) (180000,)
160657 1735
7648 9960

FA FR TA TR 0.0106840238435 0.434348023626 0.565651976374 0.989315976156

VALIDATION DATA
0.950944444444 0.132510166979
(18000,) (18000,)
16211 125
758 906

FA FR TA TR 0.00765181194907 0.455528846154 0.544471153846 0.992348188051
0.132510166979  - val loss
0.132250548498  - final_loss
Inside Plateau  2



38  iteration
1.953125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1465 - acc: 0.9475 - val_loss: 0.1325 - val_acc: 0.9508
(180000,) (180000,)
160640 1752
7614 9994

FA FR TA TR 0.0107887088034 0.432417083144 0.567582916856 0.989211291197

VALIDATION DATA
0.950833333333 0.132454383804
(18000,) (18000,)
16207 129
756 908

FA FR TA TR 0.00789666993144 0.454326923077 0.545673076923 0.992103330069
0.132454383804  - val loss
0.132250548498  - final_loss
Inside Plateau  3



38  iteration
1.953125e-05  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1465 - acc: 0.9472 - val_loss: 0.1326 - val_acc: 0.9510
(180000,) (180000,)
160675 1717
7673 9935

FA FR TA TR 0.0105731809449 0.435767832803 0.564232167197 0.989426819055

VALIDATION DATA
0.951 0.132556405326
(18000,) (18000,)
16213 123
759 905

FA FR TA TR 0.00752938295788 0.456129807692 0.543870192308 0.992470617042
0.132556405326  - val loss
0.132250548498  - final_loss
Reducing the learning rate by half



38  iteration
9.765625e-06  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1460 - acc: 0.9473 - val_loss: 0.1324 - val_acc: 0.9508
(180000,) (180000,)
160636 1756
7613 9995

FA FR TA TR 0.0108133405586 0.432360290777 0.567639709223 0.989186659441

VALIDATION DATA
0.950833333333 0.13244902482
(18000,) (18000,)
16207 129
756 908

FA FR TA TR 0.00789666993144 0.454326923077 0.545673076923 0.992103330069
0.13244902482  - val loss
0.132250548498  - final_loss
Inside Plateau  1



38  iteration
9.765625e-06  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1464 - acc: 0.9470 - val_loss: 0.1325 - val_acc: 0.9509
(180000,) (180000,)
160650 1742
7640 9968

FA FR TA TR 0.0107271294152 0.433893684689 0.566106315311 0.989272870585

VALIDATION DATA
0.950888888889 0.132491213842
(18000,) (18000,)
16208 128
756 908

FA FR TA TR 0.00783545543585 0.454326923077 0.545673076923 0.992164544564
0.132491213842  - val loss
0.132250548498  - final_loss
Inside Plateau  2



38  iteration
9.765625e-06  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1465 - acc: 0.9470 - val_loss: 0.1325 - val_acc: 0.9508
(180000,) (180000,)
160637 1755
7616 9992

FA FR TA TR 0.0108071826198 0.432530667878 0.567469332122 0.98919281738

VALIDATION DATA
0.950833333333 0.13246243605
(18000,) (18000,)
16207 129
756 908

FA FR TA TR 0.00789666993144 0.454326923077 0.545673076923 0.992103330069
0.13246243605  - val loss
0.132250548498  - final_loss
Inside Plateau  3



38  iteration
9.765625e-06  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1460 - acc: 0.9471 - val_loss: 0.1326 - val_acc: 0.9511
(180000,) (180000,)
160693 1699
7695 9913

FA FR TA TR 0.0104623380462 0.43701726488 0.56298273512 0.989537661954

VALIDATION DATA
0.951111111111 0.132618850887
(18000,) (18000,)
16215 121
759 905

FA FR TA TR 0.0074069539667 0.456129807692 0.543870192308 0.992593046033
0.132618850887  - val loss
0.132250548498  - final_loss
Reducing the learning rate by half



38  iteration
4.8828125e-06  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1461 - acc: 0.9472 - val_loss: 0.1326 - val_acc: 0.9511
(180000,) (180000,)
160674 1718
7677 9931

FA FR TA TR 0.0105793388837 0.435995002272 0.564004997728 0.989420661116

VALIDATION DATA
0.951055555556 0.132566471653
(18000,) (18000,)
16214 122
759 905

FA FR TA TR 0.00746816846229 0.456129807692 0.543870192308 0.992531831538
0.132566471653  - val loss
0.132250548498  - final_loss
Inside Plateau  1



38  iteration
4.8828125e-06  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1467 - acc: 0.9470 - val_loss: 0.1325 - val_acc: 0.9509
(180000,) (180000,)
160644 1748
7625 9983

FA FR TA TR 0.0107640770481 0.433041799182 0.566958200818 0.989235922952

VALIDATION DATA
0.950888888889 0.132474673612
(18000,) (18000,)
16208 128
756 908

FA FR TA TR 0.00783545543585 0.454326923077 0.545673076923 0.992164544564
0.132474673612  - val loss
0.132250548498  - final_loss
Inside Plateau  2



38  iteration
4.8828125e-06  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
47s - loss: 0.1464 - acc: 0.9470 - val_loss: 0.1324 - val_acc: 0.9508
(180000,) (180000,)
160627 1765
7598 10010

FA FR TA TR 0.010868762008 0.43150840527 0.56849159473 0.989131237992

VALIDATION DATA
0.950777777778 0.132417548094
(18000,) (18000,)
16204 132
754 910

FA FR TA TR 0.00808031341822 0.453125 0.546875 0.991919686582
0.132417548094  - val loss
0.132250548498  - final_loss
Inside Plateau  3



38  iteration
4.8828125e-06  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
46s - loss: 0.1461 - acc: 0.9471 - val_loss: 0.1324 - val_acc: 0.9508
(180000,) (180000,)
160622 1770
7591 10017

FA FR TA TR 0.0108995517021 0.431110858701 0.568889141299 0.989100448298

VALIDATION DATA
0.950833333333 0.132406132913
(18000,) (18000,)
16204 132
753 911

FA FR TA TR 0.00808031341822 0.452524038462 0.547475961538 0.991919686582
0.132406132913  - val loss
0.132250548498  - final_loss
Reducing the learning rate by half
   32/18000 [..............................] - ETA: 2s  448/18000 [..............................] - ETA: 2s  864/18000 [>.............................] - ETA: 2s 1312/18000 [=>............................] - ETA: 2s 1760/18000 [=>............................] - ETA: 1s 2240/18000 [==>...........................] - ETA: 1s 2688/18000 [===>..........................] - ETA: 1s 3136/18000 [====>.........................] - ETA: 1s 3616/18000 [=====>........................] - ETA: 1s 4096/18000 [=====>........................] - ETA: 1s 4576/18000 [======>.......................] - ETA: 1s 5024/18000 [=======>......................] - ETA: 1s 5472/18000 [========>.....................] - ETA: 1s 5920/18000 [========>.....................] - ETA: 1s 6368/18000 [=========>....................] - ETA: 1s 6816/18000 [==========>...................] - ETA: 1s 7264/18000 [===========>..................] - ETA: 1s 7712/18000 [===========>..................] - ETA: 1s 8160/18000 [============>.................] - ETA: 1s 8608/18000 [=============>................] - ETA: 1s 9056/18000 [==============>...............] - ETA: 1s 9504/18000 [==============>...............] - ETA: 0s 9952/18000 [===============>..............] - ETA: 0s10368/18000 [================>.............] - ETA: 0s10816/18000 [=================>............] - ETA: 0s11264/18000 [=================>............] - ETA: 0s11712/18000 [==================>...........] - ETA: 0s12160/18000 [===================>..........] - ETA: 0s12640/18000 [====================>.........] - ETA: 0s13088/18000 [====================>.........] - ETA: 0s13536/18000 [=====================>........] - ETA: 0s13984/18000 [======================>.......] - ETA: 0s14432/18000 [=======================>......] - ETA: 0s14880/18000 [=======================>......] - ETA: 0s15328/18000 [========================>.....] - ETA: 0s15776/18000 [=========================>....] - ETA: 0s16224/18000 [==========================>...] - ETA: 0s16672/18000 [==========================>...] - ETA: 0s17120/18000 [===========================>..] - ETA: 0s17568/18000 [============================>.] - ETA: 0s18000/18000 [==============================] - 2s     

ROC AREA 0.961537413093
(18000,) (18000,)
