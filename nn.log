
train images/masks shape:
(18, 1, 565, 565)
train images range (min-max): 0.0 - 1.0
train masks are within 0-1

patches per full image: 10000

train PATCHES images/masks shape:
(180000, 1, 27, 27)
train PATCHES images range (min-max): 0.0 - 1.0

train images/masks shape:
(2, 1, 565, 565)
train images range (min-max): 0.0 - 1.0
train masks are within 0-1

patches per full image: 9000

train PATCHES images/masks shape:
(18000, 1, 27, 27)
train PATCHES images range (min-max): 0.0 - 1.0
Check: final output of the network:
(None, 2)
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 1, 27, 27)     0                                            
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 729)           0           input_1[0][0]                    
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           186880      flatten_1[0][0]                  
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 2)             514         dense_1[0][0]                    
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 2)             0           dense_2[0][0]                    
====================================================================================================
Total params: 187,394
Trainable params: 187,394
Non-trainable params: 0
____________________________________________________________________________________________________



1  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from inf to 0.27719, saving model to ./test/nn/test-weights-0.27719.h5
Epoch 00000: val_loss improved from inf to 0.27719, saving model to ./test/nn/test_best_weights.h5
15s - loss: 0.3105 - acc: 0.8993 - val_loss: 0.2772 - val_acc: 0.9061
(180000,) (180000,)
161983 95
17892 30

FA FR TA TR 0.000586137538716 0.998326079679 0.00167392032139 0.999413862461

VALIDATION DATA
0.906111111111 0.277193027404
(18000,) (18000,)
16306 1
1689 4

FA FR TA TR 6.13233580671e-05 0.997637330183 0.00236266981689 0.999938676642
0.277193027404  - val loss
999999  - final_loss
Validation Loss decreased. Great work



2  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.27719 to 0.26389, saving model to ./test/nn/test-weights-0.26389.h5
Epoch 00000: val_loss improved from 0.27719 to 0.26389, saving model to ./test/nn/test_best_weights.h5
14s - loss: 0.2849 - acc: 0.8993 - val_loss: 0.2639 - val_acc: 0.9056
(180000,) (180000,)
161424 654
17282 640

FA FR TA TR 0.0040350942139 0.96428969981 0.0357103001897 0.995964905786

VALIDATION DATA
0.905555555556 0.263891910301
(18000,) (18000,)
16197 110
1590 103

FA FR TA TR 0.00674556938738 0.939161252215 0.060838747785 0.993254430613
0.263891910301  - val loss
0.277193027404  - final_loss
Validation Loss decreased. Great work



3  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.26389 to 0.26106, saving model to ./test/nn/test-weights-0.26106.h5
Epoch 00000: val_loss improved from 0.26389 to 0.26106, saving model to ./test/nn/test_best_weights.h5
14s - loss: 0.2795 - acc: 0.8996 - val_loss: 0.2611 - val_acc: 0.9035
(180000,) (180000,)
161237 841
17210 712

FA FR TA TR 0.00518885968484 0.960272291039 0.0397277089611 0.994811140315

VALIDATION DATA
0.9035 0.261063539757
(18000,) (18000,)
16148 159
1578 115

FA FR TA TR 0.00975041393267 0.932073242764 0.0679267572357 0.990249586067
0.261063539757  - val loss
0.263891910301  - final_loss
Validation Loss decreased. Great work



4  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.26106 to 0.25778, saving model to ./test/nn/test-weights-0.25778.h5
Epoch 00000: val_loss improved from 0.26106 to 0.25778, saving model to ./test/nn/test_best_weights.h5
14s - loss: 0.2761 - acc: 0.8997 - val_loss: 0.2578 - val_acc: 0.9016
(180000,) (180000,)
161251 827
17398 524

FA FR TA TR 0.00510248152124 0.97076219172 0.0292378082803 0.994897518479

VALIDATION DATA
0.901555555556 0.25777833226
(18000,) (18000,)
16140 167
1605 88

FA FR TA TR 0.0102410007972 0.948021264028 0.0519787359716 0.989758999203
0.25777833226  - val loss
0.261063539757  - final_loss
Validation Loss decreased. Great work



5  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2745 - acc: 0.8996 - val_loss: 0.2611 - val_acc: 0.9018
(180000,) (180000,)
160904 1174
16829 1093

FA FR TA TR 0.00724342600476 0.939013502957 0.0609864970427 0.992756573995

VALIDATION DATA
0.901833333333 0.261053092427
(18000,) (18000,)
16064 243
1524 169

FA FR TA TR 0.0149015760103 0.900177200236 0.0998227997637 0.98509842399
0.261053092427  - val loss
0.25777833226  - final_loss
Inside Plateau 1



5  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.25778 to 0.25624, saving model to ./test/nn/test-weights-0.25624.h5
Epoch 00000: val_loss improved from 0.25778 to 0.25624, saving model to ./test/nn/test_best_weights.h5
14s - loss: 0.2730 - acc: 0.8995 - val_loss: 0.2562 - val_acc: 0.9016
(180000,) (180000,)
161122 956
17152 770

FA FR TA TR 0.00589839460013 0.957036045084 0.0429639549157 0.9941016054

VALIDATION DATA
0.901555555556 0.256241428971
(18000,) (18000,)
16110 197
1575 118

FA FR TA TR 0.0120807015392 0.930301240402 0.0696987595983 0.987919298461
0.256241428971  - val loss
0.25777833226  - final_loss
Validation Loss decreased. Great work



6  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.25624 to 0.25615, saving model to ./test/nn/test-weights-0.25615.h5
Epoch 00000: val_loss improved from 0.25624 to 0.25615, saving model to ./test/nn/test_best_weights.h5
14s - loss: 0.2716 - acc: 0.9001 - val_loss: 0.2561 - val_acc: 0.9013
(180000,) (180000,)
161030 1048
17077 845

FA FR TA TR 0.00646602253236 0.952851244281 0.0471487557192 0.993533977468

VALIDATION DATA
0.901277777778 0.256149856064
(18000,) (18000,)
16095 212
1565 128

FA FR TA TR 0.0130005519102 0.924394565859 0.0756054341406 0.98699944809
0.256149856064  - val loss
0.256241428971  - final_loss
Validation Loss decreased. Great work



7  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.25615 to 0.25547, saving model to ./test/nn/test-weights-0.25547.h5
Epoch 00000: val_loss improved from 0.25615 to 0.25547, saving model to ./test/nn/test_best_weights.h5
14s - loss: 0.2713 - acc: 0.8994 - val_loss: 0.2555 - val_acc: 0.9018
(180000,) (180000,)
160923 1155
16915 1007

FA FR TA TR 0.00712619849702 0.943812074545 0.0561879254547 0.992873801503

VALIDATION DATA
0.901777777778 0.255469858554
(18000,) (18000,)
16080 227
1541 152

FA FR TA TR 0.0139204022812 0.910218546958 0.0897814530419 0.986079597719
0.255469858554  - val loss
0.256149856064  - final_loss
Validation Loss decreased. Great work



8  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2707 - acc: 0.9000 - val_loss: 0.2571 - val_acc: 0.9019
(180000,) (180000,)
160775 1303
16685 1237

FA FR TA TR 0.00803933908365 0.930978685415 0.0690213145854 0.991960660916

VALIDATION DATA
0.901944444444 0.257078711722
(18000,) (18000,)
16053 254
1511 182

FA FR TA TR 0.015576132949 0.892498523331 0.107501476669 0.984423867051
0.257078711722  - val loss
0.255469858554  - final_loss
Inside Plateau 1



8  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2701 - acc: 0.9001 - val_loss: 0.2606 - val_acc: 0.9001
(180000,) (180000,)
161152 926
17472 450

FA FR TA TR 0.00571329853527 0.974891195179 0.0251088048209 0.994286701465

VALIDATION DATA
0.900055555556 0.260558374359
(18000,) (18000,)
16122 185
1614 79

FA FR TA TR 0.0113448212424 0.953337271116 0.0466627288836 0.988655178758
0.260558374359  - val loss
0.255469858554  - final_loss
Inside Plateau 2



8  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2696 - acc: 0.9002 - val_loss: 0.2811 - val_acc: 0.9065
(180000,) (180000,)
159738 2340
15161 2761

FA FR TA TR 0.0144374930589 0.845943533088 0.154056466912 0.985562506941

VALIDATION DATA
0.9065 0.281111374617
(18000,) (18000,)
15946 361
1322 371

FA FR TA TR 0.0221377322622 0.780862374483 0.219137625517 0.977862267738
0.281111374617  - val loss
0.255469858554  - final_loss
Inside Plateau 3



8  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.25547 to 0.25366, saving model to ./test/nn/test-weights-0.25366.h5
Epoch 00000: val_loss improved from 0.25547 to 0.25366, saving model to ./test/nn/test_best_weights.h5
14s - loss: 0.2691 - acc: 0.9001 - val_loss: 0.2537 - val_acc: 0.9014
(180000,) (180000,)
160926 1152
17003 919

FA FR TA TR 0.00710768889053 0.948722240821 0.0512777591787 0.992892311109

VALIDATION DATA
0.901444444444 0.253663551529
(18000,) (18000,)
16084 223
1551 142

FA FR TA TR 0.013675108849 0.9161252215 0.0838747784997 0.986324891151
0.253663551529  - val loss
0.255469858554  - final_loss
Validation Loss decreased. Great work



9  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2684 - acc: 0.9000 - val_loss: 0.2541 - val_acc: 0.9009
(180000,) (180000,)
160845 1233
16904 1018

FA FR TA TR 0.00760744826565 0.943198303761 0.0568016962393 0.992392551734

VALIDATION DATA
0.900888888889 0.254117089589
(18000,) (18000,)
16066 241
1543 150

FA FR TA TR 0.0147789292942 0.911399881867 0.0886001181335 0.985221070706
0.254117089589  - val loss
0.253663551529  - final_loss
Inside Plateau 1



9  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2682 - acc: 0.9004 - val_loss: 0.2551 - val_acc: 0.8998
(180000,) (180000,)
160835 1243
17029 893

FA FR TA TR 0.00766914695394 0.950172971767 0.0498270282335 0.992330853046

VALIDATION DATA
0.899777777778 0.255077427646
(18000,) (18000,)
16065 242
1562 131

FA FR TA TR 0.0148402526522 0.922622563497 0.0773774365032 0.985159747348
0.255077427646  - val loss
0.253663551529  - final_loss
Inside Plateau 2



9  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2680 - acc: 0.9006 - val_loss: 0.2666 - val_acc: 0.9052
(180000,) (180000,)
160227 1851
15732 2190

FA FR TA TR 0.0114204272017 0.877803816538 0.122196183462 0.988579572798

VALIDATION DATA
0.905166666667 0.266649720033
(18000,) (18000,)
15984 323
1384 309

FA FR TA TR 0.0198074446557 0.817483756645 0.182516243355 0.980192555344
0.266649720033  - val loss
0.253663551529  - final_loss
Inside Plateau 3



9  iteration
0.01  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2677 - acc: 0.9006 - val_loss: 0.2548 - val_acc: 0.9008
(180000,) (180000,)
161029 1049
17216 706

FA FR TA TR 0.00647219240119 0.960607075103 0.0393929248968 0.993527807599

VALIDATION DATA
0.900833333333 0.254792764717
(18000,) (18000,)
16109 198
1587 106

FA FR TA TR 0.0121420248973 0.937389249852 0.0626107501477 0.987857975103
0.254792764717  - val loss
0.253663551529  - final_loss
Reducing the learning rate by half



9  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss improved from 0.25366 to 0.25246, saving model to ./test/nn/test-weights-0.25246.h5
Epoch 00000: val_loss improved from 0.25366 to 0.25246, saving model to ./test/nn/test_best_weights.h5
14s - loss: 0.2652 - acc: 0.9006 - val_loss: 0.2525 - val_acc: 0.9011
(180000,) (180000,)
160802 1276
16844 1078

FA FR TA TR 0.00787275262528 0.939850463118 0.060149536882 0.992127247375

VALIDATION DATA
0.901111111111 0.25245635987
(18000,) (18000,)
16063 244
1536 157

FA FR TA TR 0.0149628993684 0.907265209687 0.0927347903131 0.985037100632
0.25245635987  - val loss
0.253663551529  - final_loss
Validation Loss decreased. Great work



10  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2651 - acc: 0.9007 - val_loss: 0.2534 - val_acc: 0.9017
(180000,) (180000,)
160626 1452
16545 1377

FA FR TA TR 0.00895864953911 0.923167057248 0.0768329427519 0.991041350461

VALIDATION DATA
0.901722222222 0.253362937517
(18000,) (18000,)
16035 272
1497 196

FA FR TA TR 0.0166799533942 0.884229178972 0.115770821028 0.983320046606
0.253362937517  - val loss
0.25245635987  - final_loss
Inside Plateau 1



10  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2649 - acc: 0.9006 - val_loss: 0.2533 - val_acc: 0.9008
(180000,) (180000,)
160821 1257
16957 965

FA FR TA TR 0.00775552511754 0.946155562995 0.0538444370048 0.992244474882

VALIDATION DATA
0.900777777778 0.253330355022
(18000,) (18000,)
16069 238
1548 145

FA FR TA TR 0.01459495922 0.914353219138 0.0856467808624 0.98540504078
0.253330355022  - val loss
0.25245635987  - final_loss
Inside Plateau 2



10  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2650 - acc: 0.9006 - val_loss: 0.2529 - val_acc: 0.9010
(180000,) (180000,)
160783 1295
16868 1054

FA FR TA TR 0.00798998013302 0.941189599375 0.0588104006249 0.992010019867

VALIDATION DATA
0.901 0.252860730602
(18000,) (18000,)
16064 243
1539 154

FA FR TA TR 0.0149015760103 0.90903721205 0.0909627879504 0.98509842399
0.252860730602  - val loss
0.25245635987  - final_loss
Inside Plateau 3



10  iteration
0.005  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
15s - loss: 0.2647 - acc: 0.9008 - val_loss: 0.2547 - val_acc: 0.9022
(180000,) (180000,)
160527 1551
16325 1597

FA FR TA TR 0.00956946655314 0.910891641558 0.0891083584421 0.990430533447

VALIDATION DATA
0.902166666667 0.254727725599
(18000,) (18000,)
16013 294
1467 226

FA FR TA TR 0.0180290672717 0.866509155346 0.133490844654 0.981970932728
0.254727725599  - val loss
0.25245635987  - final_loss
Reducing the learning rate by half



10  iteration
0.0025  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2637 - acc: 0.9011 - val_loss: 0.2586 - val_acc: 0.9041
(180000,) (180000,)
160305 1773
15878 2044

FA FR TA TR 0.0109391774331 0.885950228769 0.114049771231 0.989060822567

VALIDATION DATA
0.904111111111 0.258613056302
(18000,) (18000,)
15986 321
1405 288

FA FR TA TR 0.0196847979395 0.829887773184 0.170112226816 0.98031520206
0.258613056302  - val loss
0.25245635987  - final_loss
Inside Plateau 1



10  iteration
0.0025  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
14s - loss: 0.2636 - acc: 0.9012 - val_loss: 0.2578 - val_acc: 0.9042
(180000,) (180000,)
160337 1741
15922 2000

FA FR TA TR 0.0107417416306 0.888405311907 0.111594688093 0.989258258369

VALIDATION DATA
0.904222222222 0.25782776161
(18000,) (18000,)
15989 318
1406 287

FA FR TA TR 0.0195008278653 0.830478440638 0.169521559362 0.980499172135
0.25782776161  - val loss
0.25245635987  - final_loss
Inside Plateau 2



10  iteration
0.0025  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
15s - loss: 0.2635 - acc: 0.9012 - val_loss: 0.2531 - val_acc: 0.9026
(180000,) (180000,)
160534 1544
16387 1535

FA FR TA TR 0.00952627747134 0.914351076889 0.0856489231113 0.990473722529

VALIDATION DATA
0.902555555556 0.253088042246
(18000,) (18000,)
16023 284
1470 223

FA FR TA TR 0.0174158336911 0.868281157708 0.131718842292 0.982584166309
0.253088042246  - val loss
0.25245635987  - final_loss
Inside Plateau 3



10  iteration
0.0025  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
15s - loss: 0.2634 - acc: 0.9011 - val_loss: 0.2578 - val_acc: 0.9042
(180000,) (180000,)
160317 1761
15885 2037

FA FR TA TR 0.0108651390071 0.886340810177 0.113659189823 0.989134860993

VALIDATION DATA
0.904222222222 0.257774027295
(18000,) (18000,)
15988 319
1405 288

FA FR TA TR 0.0195621512234 0.829887773184 0.170112226816 0.980437848777
0.257774027295  - val loss
0.25245635987  - final_loss
Reducing the learning rate by half



10  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
15s - loss: 0.2629 - acc: 0.9012 - val_loss: 0.2567 - val_acc: 0.9039
(180000,) (180000,)
160368 1710
15975 1947

FA FR TA TR 0.0105504756969 0.891362571142 0.108637428858 0.989449524303

VALIDATION DATA
0.903888888889 0.25668110719
(18000,) (18000,)
15992 315
1415 278

FA FR TA TR 0.0193168577911 0.835794447726 0.164205552274 0.980683142209
0.25668110719  - val loss
0.25245635987  - final_loss
Inside Plateau 1



10  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
15s - loss: 0.2629 - acc: 0.9014 - val_loss: 0.2531 - val_acc: 0.9021
(180000,) (180000,)
160562 1516
16386 1536

FA FR TA TR 0.00935352114414 0.914295279545 0.0857047204553 0.990646478856

VALIDATION DATA
0.902111111111 0.253136931684
(18000,) (18000,)
16022 285
1477 216

FA FR TA TR 0.0174771570491 0.872415829888 0.127584170112 0.982522842951
0.253136931684  - val loss
0.25245635987  - final_loss
Inside Plateau 2



10  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
15s - loss: 0.2628 - acc: 0.9013 - val_loss: 0.2544 - val_acc: 0.9027
(180000,) (180000,)
160460 1618
16203 1719

FA FR TA TR 0.00998284776466 0.904084365584 0.0959156344158 0.990017152235

VALIDATION DATA
0.902722222222 0.254394382954
(18000,) (18000,)
16009 298
1453 240

FA FR TA TR 0.018274360704 0.858239810986 0.141760189014 0.981725639296
0.254394382954  - val loss
0.25245635987  - final_loss
Inside Plateau 3



10  iteration
0.00125  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
15s - loss: 0.2627 - acc: 0.9013 - val_loss: 0.2563 - val_acc: 0.9039
(180000,) (180000,)
160369 1709
15970 1952

FA FR TA TR 0.0105443058281 0.891083584421 0.108916415579 0.989455694172

VALIDATION DATA
0.903888888889 0.256289498819
(18000,) (18000,)
15992 315
1415 278

FA FR TA TR 0.0193168577911 0.835794447726 0.164205552274 0.980683142209
0.256289498819  - val loss
0.25245635987  - final_loss
Reducing the learning rate by half



10  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
15s - loss: 0.2625 - acc: 0.9013 - val_loss: 0.2532 - val_acc: 0.9024
(180000,) (180000,)
160530 1548
16338 1584

FA FR TA TR 0.00955095694666 0.91161700703 0.0883829929695 0.990449043053

VALIDATION DATA
0.902388888889 0.253206853761
(18000,) (18000,)
16017 290
1467 226

FA FR TA TR 0.0177837738395 0.866509155346 0.133490844654 0.982216226161
0.253206853761  - val loss
0.25245635987  - final_loss
Inside Plateau 1



10  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
15s - loss: 0.2625 - acc: 0.9014 - val_loss: 0.2551 - val_acc: 0.9034
(180000,) (180000,)
160403 1675
16079 1843

FA FR TA TR 0.0103345302879 0.897165494922 0.102834505078 0.989665469712

VALIDATION DATA
0.903444444444 0.255098048899
(18000,) (18000,)
15998 309
1429 264

FA FR TA TR 0.0189489176427 0.844063792085 0.155936207915 0.981051082357
0.255098048899  - val loss
0.25245635987  - final_loss
Inside Plateau 2



10  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
15s - loss: 0.2624 - acc: 0.9014 - val_loss: 0.2552 - val_acc: 0.9034
(180000,) (180000,)
160395 1683
16060 1862

FA FR TA TR 0.0103838892385 0.896105345386 0.103894654614 0.989616110761

VALIDATION DATA
0.903444444444 0.255191110452
(18000,) (18000,)
15995 312
1426 267

FA FR TA TR 0.0191328877169 0.842291789722 0.157708210278 0.980867112283
0.255191110452  - val loss
0.25245635987  - final_loss
Inside Plateau 3



10  iteration
0.000625  learning rate

TRAIN DATA
Train on 180000 samples, validate on 18000 samples
Epoch 1/1
Epoch 00000: val_loss did not improve
Epoch 00000: val_loss did not improve
15s - loss: 0.2625 - acc: 0.9014 - val_loss: 0.2535 - val_acc: 0.9026
(180000,) (180000,)
160506 1572
16269 1653

FA FR TA TR 0.00969903379854 0.907766990291 0.0922330097087 0.990300966201

VALIDATION DATA
0.902611111111 0.253505512344
(18000,) (18000,)
16012 295
1458 235

FA FR TA TR 0.0180903906298 0.861193148258 0.138806851742 0.98190960937
0.253505512344  - val loss
0.25245635987  - final_loss
Reducing the learning rate by half
   32/18000 [..............................] - ETA: 0s